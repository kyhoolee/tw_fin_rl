{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0daa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking folder: /home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split\n",
      "  Raw files: 7400\n",
      "  Filtered files: 7402\n",
      "  Manifest files: 7400\n",
      "  Total rows in filtered: 210769\n",
      "  Empty filtered files: 1354\n",
      "   → gdelt_filtered_BNB_2020-08-12_0900_1200_134f6fc592247854.parquet, gdelt_filtered_BNB_2020-08-13_0900_1200_726b3689988d0ded.parquet, gdelt_filtered_BNB_2020-08-14_0900_1200_61116ddafbae152e.parquet, gdelt_filtered_BNB_2020-08-15_0900_1200_af6e51e65c7989d9.parquet, gdelt_filtered_BNB_2020-08-19_0900_1200_1415df204170dc7b.parquet, gdelt_filtered_BNB_2020-08-22_0900_1200_402b59824b3b077c.parquet, gdelt_filtered_BNB_2020-08-23_0900_1200_a99747c1bbdb9e89.parquet, gdelt_filtered_BNB_2020-08-24_0900_1200_bd6d4d7686c327fe.parquet, gdelt_filtered_BNB_2020-08-28_0900_1200_5c05ad5a1032fe99.parquet, gdelt_filtered_BNB_2020-08-29_0900_1200_7159e84c0ad99880.parquet ...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def check_gdelt_folder(base_dir: str):\n",
    "    base = Path(base_dir)\n",
    "    raw_dir = base / \"raw\"\n",
    "    flt_dir = base / \"filtered\"\n",
    "    man_dir = base / \"_manifest\"\n",
    "\n",
    "    print(f\"[INFO] Checking folder: {base.resolve()}\")\n",
    "\n",
    "    # 1. Đếm file\n",
    "    n_raw = len(list(raw_dir.glob(\"*.parquet\"))) if raw_dir.exists() else 0\n",
    "    n_flt = len(list(flt_dir.glob(\"*.parquet\"))) if flt_dir.exists() else 0\n",
    "    n_man = len(list(man_dir.glob(\"*.json\"))) if man_dir.exists() else 0\n",
    "    print(f\"  Raw files: {n_raw}\")\n",
    "    print(f\"  Filtered files: {n_flt}\")\n",
    "    print(f\"  Manifest files: {n_man}\")\n",
    "\n",
    "    # 2. Load thử một số file filtered\n",
    "    counts = []\n",
    "    if flt_dir.exists():\n",
    "        for p in sorted(flt_dir.glob(\"*.parquet\")):\n",
    "            try:\n",
    "                df = pd.read_parquet(p)\n",
    "                counts.append((p.name, len(df)))\n",
    "            except Exception as e:\n",
    "                counts.append((p.name, f\"ERR {e}\"))\n",
    "\n",
    "    if counts:\n",
    "        total_rows = sum(c for _, c in counts if isinstance(c, int))\n",
    "        empty_files = [f for f, c in counts if c == 0]\n",
    "        print(f\"  Total rows in filtered: {total_rows}\")\n",
    "        print(f\"  Empty filtered files: {len(empty_files)}\")\n",
    "        if empty_files:\n",
    "            print(\"   → \" + \", \".join(empty_files[:10]) + (\" ...\" if len(empty_files) > 10 else \"\"))\n",
    "    else:\n",
    "        print(\"  (no filtered files to check)\")\n",
    "\n",
    "\n",
    "# ví dụ chạy\n",
    "check_gdelt_folder(\"../../work/data/gdelt_full_hardfix_split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed2fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking MERGED under: /home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split\n",
      "  Merged files: 2\n",
      "  Total rows in merged: 160804\n",
      "  Empty merged files: 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick check for MERGED parquet files:\n",
    "- Tự động tìm các file có 'merged' trong tên hoặc nằm trong thư mục 'merged/'\n",
    "- Đếm số dòng mà không load toàn bộ (dùng pyarrow ParquetFile)\n",
    "- In thống kê: số file, tổng số dòng, số file rỗng, liệt kê vài file rỗng\n",
    "\n",
    "Usage:\n",
    "  python check_merged_parquet.py /path/to/base_dir\n",
    "  # tuỳ chọn: chỉ định glob riêng\n",
    "  python check_merged_parquet.py /data --glob \"**/merged/*.parquet\"\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import pyarrow.parquet as pq\n",
    "except ImportError:\n",
    "    print(\"[ERROR] Please install pyarrow: pip install pyarrow\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "def count_rows_parquet(fp: Path) -> int:\n",
    "    try:\n",
    "        pf = pq.ParquetFile(fp)\n",
    "        md = pf.metadata\n",
    "        return sum(md.row_group(i).num_rows for i in range(md.num_row_groups))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Can't read {fp}: {e}\")\n",
    "        return -1  # unreadable\n",
    "\n",
    "def looks_merged(p: Path) -> bool:\n",
    "    name_has = 'merged' in p.name.lower()\n",
    "    folder_has = any(part.lower() == 'merged' for part in p.parts)\n",
    "    return name_has or folder_has\n",
    "\n",
    "def find_merged_files(base: Path, custom_glob: str | None) -> list[Path]:\n",
    "    if custom_glob:\n",
    "        return sorted(base.glob(custom_glob))\n",
    "    # Mặc định: hai pattern phổ biến\n",
    "    found = set()\n",
    "    for pat in (\"**/*merged*.parquet\", \"**/merged/*.parquet\"):\n",
    "        for fp in base.glob(pat):\n",
    "            found.add(fp)\n",
    "    # Fallback: toàn bộ parquet rồi lọc bằng looks_merged\n",
    "    if not found:\n",
    "        found = {p for p in base.glob(\"**/*.parquet\") if looks_merged(p)}\n",
    "    return sorted(found)\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python check_merged_parquet.py <base_dir> [--glob \\\"**/merged/*.parquet\\\"]\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    base = Path(sys.argv[1]).expanduser().resolve()\n",
    "    custom_glob = None\n",
    "    if len(sys.argv) >= 4 and sys.argv[2] == \"--glob\":\n",
    "        custom_glob = sys.argv[3]\n",
    "\n",
    "    merged_files = find_merged_files(base, custom_glob)\n",
    "    print(f\"[INFO] Checking MERGED under: {base}\")\n",
    "    print(f\"  Merged files: {len(merged_files)}\")\n",
    "\n",
    "    total_rows = 0\n",
    "    empty_names = []\n",
    "    unreadable = 0\n",
    "\n",
    "    for fp in merged_files:\n",
    "        rows = count_rows_parquet(fp)\n",
    "        if rows < 0:\n",
    "            unreadable += 1\n",
    "            continue\n",
    "        total_rows += rows\n",
    "        if rows == 0 and len(empty_names) < 30:\n",
    "            empty_names.append(fp.name)\n",
    "\n",
    "    print(f\"  Total rows in merged: {total_rows}\")\n",
    "    print(f\"  Empty merged files: {len(empty_names)}\")\n",
    "    if empty_names:\n",
    "        print(\"   → \" + \", \".join(empty_names) + (\" ...\" if len(empty_names) == 30 else \"\"))\n",
    "    if unreadable:\n",
    "        print(f\"  [WARN] Unreadable merged files: {unreadable}\")\n",
    "\n",
    "import sys\n",
    "\n",
    "# giả lập lệnh:\n",
    "# python check_merged_parquet.py /home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split\n",
    "sys.argv = [\n",
    "    \"check_merged_parquet.py\",\n",
    "    \"/home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split\"\n",
    "]\n",
    "\n",
    "# gọi hàm main trong notebook\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2485b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading /home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split/filtered/gdelt_filtered_merged_2020-08-11_2025-09-03.parquet ...\n",
      "[INFO] Loading /home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split/filtered/gdelt_raw_merged_2020-08-11_2025-09-03.parquet ...\n",
      "{'BNB': {'langs': None,\n",
      "         'n_articles': 3266,\n",
      "         'sample_titles': ['Binance Cryptocurrency Auto Trading App',\n",
      "                           'Elliptic adds BNB to its blockchain analytics '\n",
      "                           'platform',\n",
      "                           'US 1844907O588 Binance ! # AK56 #! ~recognizes '\n",
      "                           'importances Customer of Awareness ddsSS - '\n",
      "                           'Minnesota Twins Talk'],\n",
      "         'sources': None,\n",
      "         'time_range': (datetime.date(2020, 8, 16), datetime.date(2025, 9, 3))},\n",
      " 'BTC': {'langs': None,\n",
      "         'n_articles': 24930,\n",
      "         'sample_titles': ['Bitcoin Breaks All - Time High Against Argentine '\n",
      "                           'Peso , Turkish Lira , Brazillian Real',\n",
      "                           'Bitcoin volatility surges amid flirtation with $12 '\n",
      "                           '000 threshold',\n",
      "                           'KB Kookmin Bank , Hashed partner for Bitcoin '\n",
      "                           'custody services'],\n",
      "         'sources': None,\n",
      "         'time_range': (datetime.date(2020, 8, 11), datetime.date(2025, 9, 3))},\n",
      " 'ETH': {'langs': None,\n",
      "         'n_articles': 4491,\n",
      "         'sample_titles': ['Top 3 Price Prediction Bitcoin , Ethereum , Ripple '\n",
      "                           ': Euphoria warns of danger',\n",
      "                           'Ethereum Classic Price Analysis : ETC / USD lock - '\n",
      "                           'step trading delays breakout beyond $7 . 20',\n",
      "                           'Ethereum miner revenue touched almost a two - year '\n",
      "                           'high in July'],\n",
      "         'sources': None,\n",
      "         'time_range': (datetime.date(2020, 8, 11), datetime.date(2025, 9, 2))},\n",
      " 'SOL': {'langs': None,\n",
      "         'n_articles': 1448,\n",
      "         'sample_titles': ['Solana Beach school board passes resolution in '\n",
      "                           'opposition of Measure S',\n",
      "                           'Parents push back against Solana Beach School '\n",
      "                           'phased reopening',\n",
      "                           'citybizlist : New York : Sandata Acquires Solana'],\n",
      "         'sources': None,\n",
      "         'time_range': (datetime.date(2020, 10, 13),\n",
      "                        datetime.date(2025, 9, 2))}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_merged(base_dir: str, glob_pat: str = \"**/*merged*.parquet\"):\n",
    "    base = Path(base_dir).expanduser().resolve()\n",
    "    files = sorted(base.glob(glob_pat))\n",
    "\n",
    "    dfs = []\n",
    "    for fp in files:\n",
    "        print(f\"[INFO] Loading {fp} ...\")\n",
    "        try:\n",
    "            df = pd.read_parquet(fp)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"  [WARN] Can't read {fp}: {e}\")\n",
    "    if not dfs:\n",
    "        return None\n",
    "    \n",
    "    data = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Xác định token từ cột 'symbol' (nếu có)\n",
    "    if \"symbol\" in data.columns:\n",
    "        tokens = data[\"symbol\"].unique().tolist()\n",
    "    else:\n",
    "        # fallback: đoán từ text\n",
    "        tokens = [\"BTC\",\"ETH\",\"BNB\",\"SOL\"]\n",
    "\n",
    "    results = {}\n",
    "    for token in tokens:\n",
    "        # chọn subset theo cột 'symbol'\n",
    "        if \"symbol\" in data.columns:\n",
    "            sub = data[data[\"symbol\"] == token]\n",
    "        else:\n",
    "            mask = data[\"text\"].str.contains(token, case=False, na=False)\n",
    "            sub = data[mask]\n",
    "        \n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        results[token] = {\n",
    "            \"n_articles\": len(sub),\n",
    "            \"time_range\": (sub[\"date\"].min(), sub[\"date\"].max()) if \"date\" in sub.columns else None,\n",
    "            \"sources\": sub[\"source\"].nunique() if \"source\" in sub.columns else None,\n",
    "            \"langs\": sub[\"lang\"].value_counts().head(5).to_dict() if \"lang\" in sub.columns else None,\n",
    "            \"sample_titles\": sub[\"title\"].dropna().head(3).tolist() if \"title\" in sub.columns else None\n",
    "        }\n",
    "    return results, data\n",
    "\n",
    "# Chạy:\n",
    "stats, df_all = analyze_merged(\"/home/kylh/phd/tw_fin_rl/work/data/gdelt_full_hardfix_split\")\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fin_rl)",
   "language": "python",
   "name": "fin_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
